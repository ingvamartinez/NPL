{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUT OF CORE\n",
    "### Crecacion de models con conjuntos de datos muy grandes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ingva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    \"\"\"\n",
    "    Se crea la funcion que tokenizara por medio de la funcion split\n",
    "    \"\"\"\n",
    "    text = re.sub('<[^>]*>','',text)\n",
    "    emo = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text)\n",
    "    text = (re.sub('[\\W]+','',text.lower())+' '.join(emo).replace('-',''))\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    \"\"\"\n",
    "    Permite extraer linea a linea los docs del file\n",
    "    \"\"\"\n",
    "    with open(path,'r',encoding='utf-8') as csv:\n",
    "        next(csv)\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"The infamous Ed Wood \"\"classic\"\" Plan 9 From Outer Space features an indignant alien calling the human race, \"\"...stupid! Stupid, stupid stupid!\"\" I\\'d have to say exhibit A in that trial would probably this movie, a ridiculously silly sci-fi film.<br /><br />Falling action star Jean Claude Van Damme returns to a hit role for him from the original movie, Luke, a former Universal Soldier who now works making really good universal soldiers. While Van Damme was too big to reprise the role in the first two sequels, he was too small to do much of anything else by the time the fourth film in the Universal Soldier series came around. So, probably cursing under his breath the whole way, he kicks and grunts and scowls through ninety minutes of explosions and karate kicks. You\\'ll find plenty of mindless violence, but I\\'d advise you get a coat check for your brain at the door when you start watching this thing. Otherwise, you are liable to forget where you left it by the time it\\'s over.<br /><br />Luke is called into action against more Universal Soldiers after a really really REALLY evil computer named Seth (makes HAL look like Ghandi) turns all the other universal soldiers into evil, remorseless killers. Of course this is what these things are programmed to do, but in this case they are killing their creators, not \"\"the enemy\"\" so that\\'s a problem.<br /><br />I love the dumb logic of this movie. Logic that believes that a supercomputer would create a body for itself that looks as ashamed as Michael Jai White does to be in this movie. Logic that dictates that the creator of Seth be a blue-haired cyber-stereotype geek who spouts cliches more regularly than Old Faithful does steam. Logic that has a climactic karate fight feature two characters kicking each other though ten separate panes of shattering glass in the span of three minutes of screen time.<br /><br />The film also features a daughter in peril character, wrestler Bill Goldberg as a wrestler disguised as a Universal Soldier, and a romance so tacked on, I have to think the writers thought tacked on romances were actually a GOOD thing. And when this movie ends, it ends. Not a minute after a gigantic towering finale-style explosion are the credits running. No epilogue, no where are they now, no final kiss, just explosion, hug, over. Even the creators want to get out of this thing as soon as possible.<br /><br />While it\\'s no Plan 9, US:TR is a silly little trifle of an action movie that would be fun at parties full of rowdy Van Damme fans who enjoy seeing their hero really reaching new depths. Not to be seen on a serious stomach.\"',\n",
       " 0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prueba de stream_docs\n",
    "next(stream_docs('movie_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_mnibatch(doc_stream, size):\n",
    "    \"\"\" \n",
    "    permitira obtener subconjuntos, con size que nos dara el tama√±o de las secuencias\n",
    "    que se extraera\n",
    "    \"\"\"\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#se realiza la vectorizacion con hashingvectorizer\n",
    "vect=HashingVectorizer(decode_error='ignore', n_features=2**21,\n",
    "                       preprocessor=None,tokenizer=tokenizer,ngram_range=(1,1))\n",
    "#creamos una instacion de gradiente en desenso clasificador como logistico \"loss=log\"\n",
    "clf=SGDClassifier(loss='log_loss', random_state=1,max_iter=1)\n",
    "doc_stream = stream_docs(path='movie_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [####################          ] 100% | ETA: 00:00:02"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyprind\n",
    "pbar = pyprind.ProgBar(45)\n",
    "classes = np.array([0,1])\n",
    "# tomare 45 sudconjunto de 1000 cada uno, de los 50000, se dejan 5000 para test\n",
    "for _ in range(45):\n",
    "    X_train,y_train = get_mnibatch(doc_stream,size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train =vect.transform(X_train)\n",
    "    clf.partial_fit(X_train,y_train, classes=classes)\n",
    "    pbar.update()\n",
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4958"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test,y_test = get_mnibatch(doc_stream,size=5000)\n",
    "X_test=vect.transform(X_test)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alternate_sign': True,\n",
       " 'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'ignore',\n",
       " 'dtype': numpy.float64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'n_features': 2097152,\n",
       " 'ngram_range': (1, 1),\n",
       " 'norm': 'l2',\n",
       " 'preprocessor': None,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': <function __main__.tokenizer(text)>}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
